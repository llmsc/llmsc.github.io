---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

permalink: /
title: Home
layout: home
---

<p class="workshop-title">
  The 2<sup>nd</sup> International Workshop on Large Language Model Supply Chain Analysis <br> (LLMSC 2026)
</p>
<p class="workshop-subtitle">
  July 5, 2026, Montreal, Canada, Co-located with 
  <a href="" target="_blank"><strong>FSE'26</strong></a>
</p>

---

#### About

Welcome to the <strong>2nd International Workshop on Large Language Model Supply Chain Analysis (LLMSC)</strong>! This workshop brings together researchers, practitioners, and policymakers to discuss the challenges and opportunities in understanding, optimizing, and securing the LLM Supply Chain.

Large Language Models (LLMs) have ushered in a new era of artificial intelligence (AI), redefining what is possible in domains such as natural language understanding, text generation, and autonomous systems. However, the development and deployment of LLMs are becoming increasingly complex, involving diverse components such as massive datasets, development toolchains, pre-trained foundation models, and specialized deployment environments. This intricate process gives rise to the concept of the <strong>LLM Supply Chain</strong> ‚Äî a dynamic and interconnected ecosystem of stakeholders, dependencies, and infrastructure critical to the lifecycle of LLMs.

![Workshop Structure](assets/img/structure.png){: style="width: 90%; height: auto; display: block; margin: 0 auto;" }

The motivation of this workshop is to provide a platform for researchers, practitioners, and policymakers to discuss and share their ideas on understanding, optimizing, and securing the LLM Supply Chain. This workshop aims to achieve several goals:

- **Facilitate knowledge exchange** to share ideas and preliminary results on understanding, optimizing, and securing the LLMSC.
- **Identify open challenges and opportunities** to advance future research and practice in the LLMSC.
- **Promote responsible practices** to enhance sustainability, transparency, resilience, and security across the LLMSC ecosystem.
- **Foster collaboration** to bridge gaps between academia, industry, and policy to address the complexities of the LLMSC.

Here are some valuable resources for understanding the Large Language Model Supply Chain, its composition, risks, and security considerations:

---

<span class='anchor' id='call-for-papers'></span>

#### üì¢ **Call for Papers**

We invite submissions on topics including but not limited to:

- **LLM Supply Chain Ecosystem Modeling**
  - Modeling and analysis of open-source model or LLM toolchain ecosystems
  - Ecosystem evolution analysis over time

- **Best SE Practice for LLM Toolchain**
  - Horizontal comparison of LLM development tools
  - Developer-centric perspectives on LLM toolchains
  - Bug detection and repair for LLM development tools
  - Best practices for developing LLM-integrated applications

- **Governance of LLM Supply Chain Ecosystems**
  - Model provenance and license compliance
  - Standardization in LLM supply chain ecosystems

- **Security Analysis of Supply Chain Ecosystems**
  - Vulnerability management in emerging toolchains
  - Threat analysis in LLM-integrated applications
  - Case studies and real-world experiences with LLM infrastructure
  - New security paradigms for LLM systems

**Submission Guidelines**:

We welcome the following two types of submissions:

- **Position Papers (1-4 pages including references)**: Well-argued position or work in progress.
- **Research Papers (4-8 pages including references)**: Technical research, experience reports, empirical studies, etc.

**Requirements**:

- **Originality:** All submissions must be original and not under review elsewhere.
- **Submission Format:** All submissions must be in English and in PDF format. Papers must not exceed the page limits that are listed for each call for papers. The ACM styles have changed recently, and all authors should use the official ‚ÄúACM Primary Article Template‚Äù, as can be obtained from the **[ACM Proceedings Template](https://www.acm.org/publications/proceedings-template)** page. For Microsoft Word users, please still use the ‚ÄúInterim Template‚Äù and not the New Workflow for ACM Publications. This should result in a **two-columns format**. For LaTeX users, please refer to the `sample-sigconf.tex` example file in the template available on the ACM Proceedings Template page. To that end, each submission requires using the following booktitle:

```
\documentclass[sigconf,screen,review,anonymous]{acmart}
\acmBooktitle{Companion Proceedings of the 34th ACM Symposium on the Foundations of Software Engineering (FSE '26), June 5--9, 2026, Montreal, Canada}
```

- **Submission Site:** Papers must be submitted via the **[submission site](https://llmsc26.hotcrp.com)** by **February 12th, 2026 (AoE)**.
- **Publication Date:** The official publication date is the date the proceedings are made available in the ACM Digital Library. This date may be up to **two weeks prior to the first day of the FSE conference**. The official publication date affects the **deadline for any patent filings** related to published work.
- **Notification:** As a published ACM author, you and your co-authors are subject to all **[ACM Publications Policies](https://www.acm.org/publications/policies/toc)**, including ACM‚Äôs new **[Publications Policy on Research Involving Human Participants and Subjects](https://www.acm.org/publications/policies/research-involving-human-participants-and-subjects)**.

**Review Process**:

- Submissions will be **peer-reviewed by at least three members** of the program committee.
- Evaluation criteria include **originality, relevance, technical soundness, and clarity of presentation**.

**Important Dates**:

All dates are 23:59:59 AoE (UTC-12h):

- **Paper Submission Deadline**: February 20th, 2026
- **Notification of Acceptance**: March 19th, 2026
- **Camera-Ready Papers Due**: April 2nd, 2026
- **Workshop Data:** July 5, 2026

---

<span class='anchor' id='organization'></span>

#### üë• **Organization**

**Organizing Committee**

{% include organizer_display_26.html %}

**Publicity & Web Chair**

- [**Shenao Wang**](https://shenaow.github.io/), Huazhong University of Science and Technology

- [**Xinyi Hou**](https://xinyi-hou.github.io/), Huazhong University of Science and Technology

---

<span class='anchor' id='pc'></span>

#### üë©‚Äçüíªüë®‚Äçüíª **Program Committee**

- [**Chengwei Liu**](https://lcwj3.github.io/), Nanyang Technological University
- [**Chuan Yan**](https://yanchuan390.github.io/), University of Queensland
- [**Guozhu Meng**](https://impillar.github.io/), Institute of Information Engineering, Chinese Academy of Sciences
- [**Kaifeng Huang**](https://kaifeng-h.github.io/), Tongji University
- [**Lingyun Ying**](https://scholar.google.com/citations?user=eJXxo-gAAAAJ&hl=zh-CN), QI-ANXIN Technology Research Institute
- [**Marius Fleischer**](https://www.linkedin.com/in/marius-fleischer/), NVIDIA
- [**Nusrat Zahan**](https://www.nzahan.net/), North Carolina State University
- [**Xiaofei Xie**](https://xiaofeixie.bitbucket.io/), Singapore Management University
- [**Xiaoyu Zhang**](https://shiningrain.github.io/), Nanyang Technological University
- [**Yuede Ji**](https://yuede.github.io/), University of Texas at Arlington
- [**Zheng Wang**](https://infocondb.org/presenter/zheng-wang), Tencent Security Xuanwu Lab

<span class='anchor' id='contact'></span>

#### üåê **Stay Connected**

- **Twitter**: **[LLMSC](https://x.com/llmscworkshop)**
- **Email**: **[llmscworkshop@gmail.com]()**

---
